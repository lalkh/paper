# -*- coding: UTF-8 -*-
from pyspark.sql import SparkSession
from pyspark.sql import Row
from pyspark.sql.types import *
import scapy
from scapy.all import *
from scapy.utils import PcapReader
import pymysql
import pandas as pd
from pyspark import SparkContext
from pyspark.sql import SQLContext
spark = SparkSession \
    .builder \
    .appName("alarm correlation") \
    .config("spark.some.config.option", "some-value") \
    .getOrCreate()
sc = spark.sparkContext
sqlc = SQLContext(sc)
df = pd.read_csv("/home/hadoop/Desktop/paper/test.csv")
sdf = sqlc.createDataFrame(df)
